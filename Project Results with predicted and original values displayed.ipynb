{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the users data file with features\n",
    "header = ['user_id', 'age', 'sex', 'occupation','zipcode']\n",
    "users_data = pd.read_table('C:\\\\Users\\\\Sirivamsi\\\\Documents\\\\Big Data\\\\Project\\\\Project Files\\\\ml-100k\\\\u.user', sep='|', names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the ratings of users on items\n",
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_table('C:\\\\Users\\\\Sirivamsi\\\\Documents\\\\Big Data\\\\Project\\\\Project Files\\\\ml-100k\\\\u.data', sep='\\t', names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(users_data, train_data, on='user_id')\n",
    "test_data = pd.merge(users_data, test_data, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the unique list of occupations in the dataset\n",
    "occupation_list = np.array(users_data.occupation.unique())\n",
    "print (occupation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the unique number of users and movies in the dataset\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print (\"Number of users = \" + str(n_users) + \" | Number of movies = \" + str(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Pearson Correlation Similarity function\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def pearson_correlation_similarity(matrix):\n",
    "   matrix_mean = np.nanmean(matrix,axis=1)\n",
    "   user_mean_subtracted = matrix - matrix_mean[:, None]\n",
    "   user_mean_subtracted = np.nan_to_num(user_mean_subtracted)\n",
    "   similaritymatrix = cosine_similarity(user_mean_subtracted)\n",
    "   np.fill_diagonal(similaritymatrix, 0)\n",
    "   return similaritymatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Adjusted Cosine Similarity function\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def adjusted_cosine_similarity(matrix):\n",
    "   matrix_mean = np.nanmean(matrix,axis=1)\n",
    "   user_mean_subtracted = matrix - matrix_mean[:, None]\n",
    "   user_mean_subtracted = np.nan_to_num(user_mean_subtracted)\n",
    "   similaritymatrix = cosine_similarity(user_mean_subtracted.T)\n",
    "   np.fill_diagonal(similaritymatrix, 0)\n",
    "   return similaritymatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition for making groups and calculating the user similarity matrices\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Takes arguments occupation type, the training/testing matrix and user similarity metric type for calculating the similarity between users\n",
    "def makegroups(occupation,data_matrix,usersimilaritymetric):\n",
    "# Checking if the matrix passed is a training set or a testing set and then generates groups\n",
    " if data_matrix.shape[0] == train_data.shape[0]:\n",
    "   train_data_with_occupation = data_matrix.loc[data_matrix['occupation'] == occupation]\n",
    "   user_id_grouped = train_data_with_occupation['user_id'].unique()\n",
    "   listofusers = []\n",
    "   listofusers = np.unique(user_id_grouped)\n",
    "   num_of_rows=np.count_nonzero(listofusers)\n",
    "   group_matrix = np.zeros((0,n_items))\n",
    "# Similarity is calculated between the users of the group\n",
    "   for i in np.nditer(listofusers):\n",
    "      temp_matrix = train_data_matrix[i-1].reshape(1,n_items)\n",
    "      group_matrix = np.append(group_matrix,temp_matrix,axis=0)\n",
    "   user_similarity = np.zeros((num_of_rows,n_items))\n",
    "# Computes similarity based on the argument passed\n",
    "   if usersimilaritymetric == 'cosine':\n",
    "     user_similarity = cosine_similarity(group_matrix)\n",
    "     np.fill_diagonal(user_similarity, 0)\n",
    "   elif usersimilaritymetric == 'pearsoncorrelation':\n",
    "     user_similarity = pearson_correlation_similarity(group_matrix)\n",
    "# User similarity matrix is concatenated with the user id's at the start of the column        \n",
    "   user_similarity = np.concatenate((listofusers[:, np.newaxis], user_similarity), axis=1)      \n",
    "   return user_similarity\n",
    " else:\n",
    "# If test data is passed, then the test users are grouped and returned         \n",
    "  test_data_with_occupation = data_matrix.loc[data_matrix['occupation'] == occupation]\n",
    "  user_id_grouped = test_data_with_occupation['user_id'].unique()\n",
    "  listoftestusers = []\n",
    "  listoftestusers = np.unique(user_id_grouped)\n",
    " return listoftestusers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from math import sqrt\n",
    "# Function to calculate the prediction and Mean Absolute Error Values\n",
    "# Takes the arguments test group, user similarity matrix computed on training data,predictions,original values, \n",
    "# k - Group Size i.e, a threshold value of 25%,50%,75% or 100% and the type of item similarity metric to be used\n",
    "def calcpredandmaetest(testgroup,user_similarity_matrix, prediction, originalvalues, k, itemsimilaritymetric, numofitems):\n",
    "  for p in np.nditer(testgroup):\n",
    "     v=0   \n",
    "     for q in user_similarity_matrix[:,0:1]:\n",
    "        v=v+1\n",
    "        if p == q:\n",
    "          noofrows = user_similarity_matrix.shape[0]\n",
    "          similardata = user_similarity_matrix[v-1,1:noofrows+1] \n",
    "# Sorting the most similar users in ascending order and storing the indexes in similarindexvalues\n",
    "          similarindexvalues = np.argsort(user_similarity_matrix[v-1,1:noofrows+1])\n",
    "          user_item_matrix = np.zeros((0,n_items))\n",
    "          totalcount = len(similarindexvalues)\n",
    "          temp = 1-k\n",
    "          getnumofusers = np.rint(totalcount*temp).astype(int)\n",
    "# Constructing user-item matrix with the most similar users\n",
    "          for z in similarindexvalues[getnumofusers:totalcount+1]:\n",
    "            similar_users = (user_similarity_matrix[z,0:1]).astype(int)\n",
    "            user_item_matrix = np.append(user_item_matrix,(train_data_matrix[similar_users-1]),axis=0) \n",
    "          if itemsimilaritymetric == 'cosine':\n",
    "            item_similarity = cosine_similarity(user_item_matrix.T)\n",
    "            np.fill_diagonal(item_similarity, 0)\n",
    "          elif itemsimilaritymetric == 'adjustedcosine':\n",
    "            item_similarity = adjusted_cosine_similarity(user_item_matrix)\n",
    "          for r in test_data.itertuples():\n",
    "\n",
    "                if r[1] == p:\n",
    "                   print (\"User id :\" + str(r[1]))\n",
    "                   print (\"Item id :\" + str(r[6]))\n",
    "                   print (\"User specified Rating :\" + str(r[7]))\n",
    "#  Sorting the most similar items in ascending order and storing the indexes in similaritemindexvalues\n",
    "                   similaritemindexvalues = np.argsort(item_similarity[r[6]-1]) \n",
    "                   numerator=0\n",
    "                   denominator=0\n",
    "                   predictedvalue=0  \n",
    "# Calculating the prediction\n",
    "                   for x in similaritemindexvalues[n_items-numofitems:n_items]:\n",
    "                       rawrating = train_data_matrix[r[1]-1,x].astype(int)\n",
    "                       if rawrating!=0:\n",
    "                          simofrating = item_similarity[r[6]-1,x]\n",
    "                          numerator = numerator + (rawrating*simofrating)\n",
    "                          denominator = denominator + item_similarity[r[6]-1,x]\n",
    "                   if denominator == 0:\n",
    "                       predictedvalue = 0\n",
    "                   else:\n",
    "                       predictedvalue = numerator/denominator \n",
    "                   print (\"Prediction :\" + str(int(round(predictedvalue))))\n",
    "                   prediction = np.append(prediction,predictedvalue)\n",
    "                   originalvalues = np.append(originalvalues,r[7])  \n",
    "# Returning the original values and prediction for every group\n",
    "  return originalvalues, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can change the values here and test the code\n",
    "import numpy as np\n",
    "results = []\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "pd = []\n",
    "ov = []\n",
    "itemsizevalue = 400\n",
    "k=1/2\n",
    "# Computing Mean Absolute Error on Training data and testing with the validation data set aside\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[6]-1] = line[7]\n",
    "# Computing Mean Absolute Error for Cosine and Adjusted Cosine\n",
    "usersimilaritymetric = 'cosine'\n",
    "itemsimilaritymetric = 'adjustedcosine'\n",
    "for abcd in ['student']:\n",
    "    similaritymatrix = makegroups(abcd,train_data,usersimilaritymetric)\n",
    "    testdata = makegroups(abcd,test_data,usersimilaritymetric)\n",
    "    ov, pd = calcpredandmaetest(testdata,similaritymatrix,pd,ov,k,itemsimilaritymetric,itemsizevalue)\n",
    "mae = mean_absolute_error(ov,pd)\n",
    "print (\"Mean Absolute Error \" + str(mean_absolute_error(ov,pd)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
